Topic 1: Adversarial Machine Learning in Cybersecurity
Academic Resource 1
1. Citation:
Rosenberg, I., Shabtai, A., Elovici, Y., & Rokach, L. (2020). Adversarial
Machine Learning Attacks and Defense Methods in the Cyber
Security Domain. arXiv preprint arXiv:2007.02407. Retrieved from
https://arxiv.org/abs/2007.02407 (arXiv)
2. Resource Type:
Academic Article
3. Synopsis:
This survey reviews adversarial attacks (e.g. evasion, poisoning)
against ML systems in cybersecurity, outlines attacker goals and
capabilities, and proposes a taxonomy mapping attacks and
corresponding defenses in security contexts. The paper also
discusses the unique challenges of deploying adversarial ML in realworld security systems (e.g. discrete feature spaces, constrained
attacker modifications).
4. Direct Link:
https://arXiv.org/abs/2007.02407 (arXiv)
5. Relevance Rating: 5/5
This is a foundational survey specifically targeted at adversarial ML in
cybersecurity, making it extremely central to your topic. Its taxonomy
and critique of deployment challenges are especially valuable.
Limitations:
• It is a survey rather than novel original research, so it may not include
the most recent developments post-2020.
• Some defense proposals may be theoretical and not validated in
large-scale real-world systems.

Academic Resource 2
1. Citation:
Papernot, N., McDaniel, P., Wu, X., Jha, S., & Swami, A. (2015).
Distillation as a Defense to Adversarial Perturbations against Deep
Neural Networks. arXiv preprint arXiv:1511.04508. Retrieved from
https://arXiv.org/abs/1511.04508 (arXiv)
2. Resource Type:
Academic Article
3. Synopsis:
This article introduces defensive distillation as a technique to
reduce the vulnerability of deep neural networks to adversarial
perturbations. The authors show that distilling knowledge from a
DNN can smooth out gradients exploited by attackers, dramatically
lowering adversarial success rates in tested settings.
4. Direct Link:
https://arXiv.org/abs/1511.04508 (arXiv)
5. Relevance Rating: 4/5
While not specific to cybersecurity per se, this is a seminal work in
adversarial defense and helps you understand core defense
mechanisms applicable across domains (including security).
Limitations:
• The experiments are largely in image domain (vision), so some
conclusions may not transfer cleanly to discrete, structured, or
domain-constrained data (e.g. network traffic).
• Later works have found that distillation can be circumvented by more
advanced adversarial strategies.

Online/Multimedia Resource 1
1. Citation (APA):
“CertMike Explains Adversarial AI.” (n.d.). YouTube. Retrieved from
https://www.youtube.com/watch?v=neGRoccTP-4 (YouTube)
2. Resource Type:
Educational YouTube Video
3. Synopsis:
In this talk, Mike Chapple introduces the notion of adversarial AI, how
machine learning models may be manipulated by adversaries, and
why it matters in cybersecurity. He breaks down concepts accessibly,
making it useful for those new to the subject.
4. Direct Link:
https://www.youtube.com/watch?v=neGRoccTP-4 (YouTube)
5. Relevance Rating: 3/5
This is a more introductory resource, good for conceptual grounding
and non-technical audiences, but not deeply technical or domain
specific.
Limitations:
• High-level, doesn’t dive into advanced methods, datasets, or
research details.
• May simplify or omit nuances for the sake of clarity.
Online / Multimedia Resource 2
1. Citation:
“Overview of Adversarial Machine Learning.” (2023, October 12).
YouTube. Software Engineering Institute / Carnegie Mellon University.
https://www.youtube.com/watch?v=C8jJ4H6BL1c
2. Resource Type:
YouTube Video
3. Synopsis:
This video provides a compact overview of adversarial machine
learning: definitions, adversary motivations, threat models,
mitigation strategies, and how robustness is achieved. It also
presents a taxonomy of attack vectors and defense techniques.
4. Direct Link:
https://www.youtube.com/watch?v=C8jJ4H6BL1c
5. Relevance Rating: 4/5
This is more technical and structured than the first video. Useful for
quickly getting up to speed and mapping out the landscape of
adversarial ML.
Limitations:
• Because it is an overview, it cannot cover every nuance or variation of
attacks/defenses.
• It might not focus specifically on cybersecurity domains (intrusion,
malware, etc.), so some adaptation is required.
